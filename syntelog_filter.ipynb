{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769f2bf0-b87d-469a-9a5c-c4d46c114737",
   "metadata": {},
   "source": [
    "### Explanation of steps to generate the syntelog files\n",
    "1: drop one of the duplicated lines <br><br>\n",
    "2: drop if excess in ATL1-4 <br><br>\n",
    "3: get rid of 0 and/or S if there are enough without it; if there are enough with 0 but without S, drop S.<br><br>\n",
    "4: drop mixed ATL chromosomes, keep if S, see next step for \"problem0\"<br><br>\n",
    "5: for problem 0s, drop the 0 if it's in the minority (i.e., chr5hap1, chr5hap2, chr5hap0, chr8hap0, drop chr8hap8 and leave the rest).  If they are equal counts still, just drop the row entirely<br><br>\n",
    "6: manually curate any remaining problem genes (3 genes at this point)<br><br>\n",
    "7: remove ones with duplications in DM and at least 1 wild, since these would be likely to be accidental merging of two genes<br><br>\n",
    "8.1: drop if doesn't contain ATL alleles <---- syntelogs_atl_only.csv<br><br>\n",
    "8.2: drop if excess in CND or M6 (based on step 7, not step 8.1) <---- syntelogs_3species.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac3b189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7602834",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/fekeann/Documents/Lab/RNAseq/Syntelogs/circadian_atl_comb_syntelogs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25806fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the file\n",
    "with open(filename) as f:\n",
    "    lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "907a7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn each line into a nested list\n",
    "# and make another version that is a flat list one geneID deep (for Pandas, later)\n",
    "split = [line.split('\\t') for line in lines]\n",
    "flat_split = [el for line in split for el in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2a1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new list of \"SyntelogIDs\" that contains the right number for each row\n",
    "split_groups = []\n",
    "for i, line in enumerate(split):\n",
    "    for j in range(len(line)):\n",
    "        split_groups.append(f\"Synt_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9737358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the flat list and the SyntelogIDs into a pandas data frame\n",
    "syntelogs = pd.DataFrame({\"Syntelog\":split_groups, \"geneID\":flat_split})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca014f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the species in the geneID\n",
    "# if it's S. tubersum, the \"species\" is actually the variety (ATL or DM)\n",
    "def determine_species(gene):\n",
    "    if \"Soltu\" in gene:\n",
    "        return gene.split(\".\")[1].split(\"_\")[0]\n",
    "    else:\n",
    "        return gene.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b143a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find which chromosome (*not* haplotype) the gene is on\n",
    "# since Soltu and Solch contain variety information while Solca and Sollyc don't\n",
    "# then it is in a different spot dependent on the species\n",
    "def determine_chrom(gene):\n",
    "    if \"Soltu\" in gene or \"Solch\" in gene:\n",
    "        gene = gene.split(\".\")[2]\n",
    "        if \"G\" in gene:\n",
    "            chrom = gene.split(\"G\")[0].split(\"_\")[0]\n",
    "        else:\n",
    "            chrom = gene[0]\n",
    "    elif \"Sollyc\" in gene or \"Solca\" in gene:\n",
    "        gene = gene.split(\".\")[1]\n",
    "        if \"G\" in gene:\n",
    "            chrom = gene.split(\"G\")[0]\n",
    "        else:\n",
    "            chrom = gene[0]\n",
    "    try:\n",
    "        return int(chrom)\n",
    "    except ValueError:\n",
    "        return(chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883a4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new columns to the data frame containing this info\n",
    "syntelogs[\"species\"] = syntelogs.geneID.apply(determine_species)\n",
    "syntelogs[\"chromosome\"] = syntelogs.geneID.apply(determine_chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbc4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_find(regex, text):\n",
    "    if re.search(regex, text):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf07bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_atl_hap(geneID):\n",
    "    # finds the haplotype for ATL gene IDs\n",
    "    # would provide meaningless results for other varieties\n",
    "    if \".S\" in geneID:\n",
    "        return \"S\"\n",
    "    else:\n",
    "        ID = geneID.split(\"_\")[2]\n",
    "        return ID[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9be28901",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_list = [\"DM\", \"Solch\", \"Solca\", \"Sollyc\", \"_0G\", \"_1G\", \"_2G\", \"_3G\", \"_4G\"]\n",
    "def quality_scorer(dataset):\n",
    "    excesscount_dict = {}\n",
    "    missingcount_dict = {}\n",
    "    atlcount_dict = {}\n",
    "    excessid_dict = {}\n",
    "    missingid_dict = {}\n",
    "    atlissues = {}\n",
    "    all_synts = dataset.Syntelog.unique()\n",
    "    total_synts = len(all_synts)\n",
    "    cur_synt = 0 #this is just for progress displays\n",
    "    for synt in all_synts:\n",
    "        cur_synt += 1\n",
    "        atl_doubles = False\n",
    "        print(f\"On Syntelog {cur_synt} of {total_synts}\", end='\\r')\n",
    "        cur_syntelog = dataset[dataset.Syntelog == synt] #filter to the one we're looking at\n",
    "        for hap in hap_list:\n",
    "            cur_count = sum(cur_syntelog.geneID.str.contains(hap)) # count how many there are in each haplotype\n",
    "            if cur_count > 1: # if there is more than one in that haplotype\n",
    "                excesscount_dict[hap] = excesscount_dict.get(hap, 0) + 1 #record that we found another\n",
    "                temp = excessid_dict.get(hap, [])\n",
    "                temp.append(synt)\n",
    "                excessid_dict[hap] = temp # and record what haplotype had the issue\n",
    "                if reg_find(\"_[1-4]G\", hap): # if the issue was in one of the phased ATL haplotypes, note it\n",
    "                    atl_doubles = True\n",
    "            elif cur_count == 0:\n",
    "                missingcount_dict[hap] = missingcount_dict.get(hap, 0) + 1 # record if something isn't there too\n",
    "                temp = missingid_dict.get(hap, [])\n",
    "                temp.append(synt)\n",
    "                missingid_dict[hap] = temp\n",
    "        cur_atl = cur_syntelog[cur_syntelog.species == \"Atl\"].copy() # now just focus on ATL\n",
    "        atl_count = cur_atl.shape[0]\n",
    "        atlcount_dict[atl_count] = atlcount_dict.get(atl_count, 0) + 1\n",
    "        cur_atl[\"Haplotype\"] = cur_atl.geneID.apply(find_atl_hap) # make a new column containing the haplotype \n",
    "        if atl_count > 4:\n",
    "            if atl_doubles == False: # if the problem is in the 0 or S haplotypes, think further\n",
    "                                     # if the problem is in a phased haplotype, we will need to discard it later.\n",
    "                cur0s = cur_atl[cur_atl.Haplotype==\"0G\"].shape[0]\n",
    "                curSs =  cur_atl[cur_atl.Haplotype==\"S\"].shape[0]\n",
    "                if atl_count - 4 == curSs: # if the entire problem is extra alleles from the scaffold, record it for removal\n",
    "                    temp = atlissues.get(\"RemoveSs\", [])\n",
    "                    temp.append(synt)\n",
    "                    atlissues[\"RemoveSs\"] = temp\n",
    "                elif atl_count - 4 < curSs: # if the problem is extra alleles from the scaffold but non-1:1 in the phased\n",
    "                    temp = atlissues.get(\"ManuallyCurateS\", [])  # mark it for manual curation\n",
    "                    temp.append(synt)\n",
    "                    atlissues[\"ManuallyCurateS\"] = temp\n",
    "                elif atl_count - 4 == cur0s: # if the entire problem is extra alleles from the unphased haplotype, record it for removal\n",
    "                    temp = atlissues.get(\"Remove0s\", [])\n",
    "                    temp.append(synt)\n",
    "                    atlissues[\"Remove0s\"] = temp\n",
    "                elif atl_count - 4 < cur0s: # if the problem is extra alleles from the unphased but non-1:1 in the phased, proceed.\n",
    "                    if len(cur_atl.chromosome.unique()) > 1: # if the unphased are on multiple chromosomes, mark\n",
    "                        temp = atlissues.get(\"Mixed0Chrom\", [])\n",
    "                        temp.append(synt)\n",
    "                        atlissues[\"Mixed0Chrom\"] = temp\n",
    "                    else:\n",
    "                        temp = atlissues.get(\"ManuallyCurate0\", []) # if there are just too many unphased, mark\n",
    "                        temp.append(synt)\n",
    "                        atlissues[\"ManuallyCurate0\"] = temp\n",
    "                elif atl_count - 4 == curSs + cur0s: # if it's perfect outside of unphased and scaffold\n",
    "                    temp = atlissues.get(\"Remove0andS\", []) # mark for removal\n",
    "                    temp.append(synt)\n",
    "                    atlissues[\"Remove0andS\"] = temp\n",
    "                else:\n",
    "                    temp = atlissues.get(\"Escaped\", []) #a catch-all for anything that didn't fall into the above categories\n",
    "                    temp.append(synt)\n",
    "                    atlissues[\"Escaped\"] = temp\n",
    "    print(\"\")\n",
    "    print(\"Excess Counts:\")\n",
    "    print(excesscount_dict)\n",
    "    print(\"Missing Counts:\")\n",
    "    print(missingcount_dict)\n",
    "    print(\"ATL Counts:\")\n",
    "    print(atlcount_dict)\n",
    "    return excessid_dict, missingid_dict, atlissues,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d58587d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Syntelog 30457 of 30457\n",
      "Excess Counts:\n",
      "{'_2G': 93, 'Solch': 119, 'Solca': 119, '_3G': 207, '_4G': 64, 'Sollyc': 69, '_0G': 371, 'DM': 137, '_1G': 135}\n",
      "Missing Counts:\n",
      "{'Solch': 7940, 'Sollyc': 9916, '_0G': 23149, '_1G': 14253, '_2G': 12634, '_3G': 12182, '_4G': 13815, 'Solca': 7189}\n",
      "ATL Counts:\n",
      "{0: 5695, 4: 11725, 1: 2828, 2: 3975, 3: 5797, 5: 384, 7: 12, 6: 32, 8: 6, 9: 2, 12: 1}\n"
     ]
    }
   ],
   "source": [
    "init_excess, init_missing, init_atl = quality_scorer(syntelogs)\n",
    "# since we don't care if there is at least one per species, then init_missing is unused\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af60418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there were a handful of rows in the initial file that were duplicated\n",
    "duped_rows = syntelogs[\"geneID\"].value_counts()>1\n",
    "duped_synts = syntelogs[syntelogs.geneID.isin(duped_rows[duped_rows==True].index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7365d74-0414-4542-9b4b-42c368c6cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "dupe_pairs = dict()\n",
    "double_dippers = []\n",
    "for gene in duped_synts.cur_synts = duped_synts[duped_synts.geneID==gene].Syntelog.to_list()\n",
    "    for i in range(2): #check both orientations\n",
    "        if cur_synts[i] in dupe_pairs.keys(): # if one is already in the keys of dupe_pairs\n",
    "            found = True\n",
    "            if cur_synts[abs(i-1)] == dupe_pairs[cur_synts[i]]: # make sure that the other pair is there\n",
    "                pass # if it's there, then we're good, can do nothing\n",
    "            else: double_dippers.append(cur_synts[i]) #otherwise record it as occuring with multiple pairings\n",
    "    if found == False:\n",
    "        dupe_pairs[cur_synts[0]] = cur_synts[1] #if we haven't seen either before, add it to the list of pairs\n",
    "\n",
    "# if the number of \"double dippers\" is 0, that means entire lines we're duplicated and we're free to just toss one.\n",
    "print(len(double_dippers))geneID.unique():\n",
    "    # go through all the duplicated ones\n",
    "    found = False\n",
    "    # find out which pairs are duplicates of eachother\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4e169bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the output of the previous cell is 0, can just keep one at random and toss the other\n",
    "# arbitrarily, we decide to keep the first (the key) and toss the second (the value)\n",
    "step1 = syntelogs[~syntelogs.Syntelog.isin(dupe_pairs.values())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59001d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_drop = [\"_1G\", \"_2G\", \"_3G\", \"_4G\"]\n",
    "step2 = step1.copy()\n",
    "# if there is a problem in the ATL phased haplotypes, get rid of that syntelog.\n",
    "for key in keys_to_drop:\n",
    "    step2 = step2[~step2.Syntelog.isin(init_excess[key])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d696f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop0G(syntelog, df):\n",
    "    \"\"\"\n",
    "    Gets rid of the unphased haplotype genes for a specific syntelog \n",
    "    syntelog: a str containing the name of the syntelog to be altered\n",
    "    df: the pandas dataframe to be alteredd\n",
    "    \"\"\"\n",
    "    cur_synt  = df[df.Syntelog == syntelog]\n",
    "    df.drop(cur_synt[cur_synt.geneID.str.contains(\"_0G\")].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5010e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropS(syntelog, df):\n",
    "    \"\"\"\n",
    "    Gets rid of the unphased scaffold genes for a specific syntelog \n",
    "    syntelog: a str containing the name of the syntelog to be altered\n",
    "    df: the pandas dataframe to be alteredd\n",
    "    \"\"\"\n",
    "    cur_synt = df[df.Syntelog == syntelog]\n",
    "    cur_atl = cur_synt[cur_synt.species == \"Atl\"]\n",
    "    df.drop(cur_atl[cur_atl.chromosome == \"S\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c4c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "step3 = step2.copy()\n",
    "# remove the 0 and S Atlantic genes as appropriate, judged by \"quality_scorer\" above\n",
    "remove0 = init_atl[\"Remove0s\"] + init_atl[\"Remove0andS\"]\n",
    "removeS = init_atl[\"RemoveSs\"] + init_atl[\"Remove0andS\"]\n",
    "[drop0G(synt, step3) for synt in remove0];\n",
    "[dropS(synt, step3) for synt in removeS];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcc9a3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Syntelog 30018 of 30018"
     ]
    }
   ],
   "source": [
    "mixed_chrom_synts = []\n",
    "mixed_chrom_on0 = []\n",
    "num_synt = step3.Syntelog.unique().shape[0]\n",
    "for i, synt in enumerate(step3.Syntelog.unique()):\n",
    "    print(f\"On Syntelog {i+1} of {num_synt}\", end='\\r')\n",
    "    cur_synt = step3[step3.Syntelog==synt]\n",
    "    cur_atl = cur_synt[cur_synt.species==\"Atl\"]\n",
    "    # look for mixed chromosome ATL synts\n",
    "    if cur_atl.chromosome.unique().shape[0] > 1:\n",
    "        cur_atl = cur_atl.copy()\n",
    "        # if it's mixed, try dropping the scaffold; if it's fixed, it's fine to keep\n",
    "        dropS(synt, cur_atl)\n",
    "        if cur_atl.chromosome.unique().shape[0] > 1:\n",
    "            drop0G(synt, cur_atl) # now try dropping the unphased\n",
    "            if cur_atl.chromosome.unique().shape[0] > 1:\n",
    "                mixed_chrom_synts.append(synt) # if that doesn't fix it, mark it one way\n",
    "            else:\n",
    "                mixed_chrom_on0.append(synt) # if the problem *is* the unphased, mark that instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "116581b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it's actually mixed (not caused by the scaffold or the unphased, get rid of it)\n",
    "step4 = step3[~step3.Syntelog.isin(mixed_chrom_synts)].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5b48adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Syntelog 92 of 92"
     ]
    }
   ],
   "source": [
    "mixed_chrom_still = []\n",
    "num_synt = len(mixed_chrom_on0)\n",
    "for i, synt in enumerate(mixed_chrom_on0): # this next bit only applies to the rows where the problem is on the unphased\n",
    "    print(f\"On Syntelog {i+1} of {num_synt}\", end='\\r')\n",
    "    cur_synt = step4[step4.Syntelog==synt]\n",
    "    cur_atl = cur_synt[cur_synt.species==\"Atl\"].copy()\n",
    "    dropS(synt, cur_atl)\n",
    "    if cur_atl.chromosome.value_counts(ascending=False).values[0] > 1: # if there is more than one chromosome after removing the S\n",
    "        keep = cur_atl.chromosome.value_counts(ascending=False).index[0] # keep the versions that belong to the majority chromosome\n",
    "        step4.drop(cur_atl[cur_atl.chromosome != keep].index, inplace=True)\n",
    "    else:\n",
    "        mixed_chrom_still.append(synt) # if there isn't a majority, mark it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d90995b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step5 = step4[~step4.Syntelog.isin(mixed_chrom_still)].copy() # keep those that aren't still problematic for mixed chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a2b01ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Syntelog 29457 of 29457\n",
      "Excess Counts:\n",
      "{'Sollyc': 47, '_0G': 320, 'DM': 80, 'Solch': 75, 'Solca': 73}\n",
      "Missing Counts:\n",
      "{'Solch': 7858, 'Sollyc': 9763, '_0G': 22740, '_1G': 13973, '_2G': 12410, '_3G': 11882, '_4G': 13408, 'Solca': 7108}\n",
      "ATL Counts:\n",
      "{0: 5695, 4: 11615, 1: 2828, 2: 3877, 3: 5439, 5: 3}\n"
     ]
    }
   ],
   "source": [
    "mod_excess, mod_missing, mod_atl = quality_scorer(step5) #figure out which still need to be manually filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2decaf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ManuallyCurateS': ['Synt_26033', 'Synt_26286'],\n",
       " 'ManuallyCurate0': ['Synt_27046']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_atl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a62565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step5[step5.Syntelog==\"Synt_27046\"]\n",
    "#BLAST Searching using the 2G005970.2 CDS as the query returns 0G007690.1 as hit #7\n",
    "#Hits 1-6 belong to different spiceoforms of the 2G, 3G, and 4G versions on this table\n",
    "#0G010330 doesn't even show up in the top 50 hits, so drop this one.\n",
    "to_drop = [\"Soltu.Atl_v3.11_0G010330.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2b15b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "step5[step5.Syntelog==\"Synt_26033\"]\n",
    "#BLAST Searching using the 10_2G014510.1 CDS as the query returns S059640.1 as hit #1\n",
    "#S059540.1 is hit #3.  The scores (e.value, ID, and query coverage) are all equal.\n",
    "#There are also versions of the one on 1, and 2 nearby too (it's likely a real duplication)\n",
    "#Since the 1 and 2 versions picked the earlier (lower) # as the syntelog,\n",
    "#I will do the same and pick S059540 as the version to keep\n",
    "to_drop.append(\"Soltu.Atl_v3.S059640.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f253a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "step5[step5.Syntelog==\"Synt_26286\"]\n",
    "#BLAST searching using the 11_1G001150.1 CDS as the query returns S006220 as \n",
    "#the 19th hit and S017940 as the 24th hit.  \n",
    "#S006220 has considerably lower e-value (1e-116 vs 4e-55), better coverage (100 vs 56.91)\n",
    "#and better TopID (96.76 vs 95.04)\n",
    "#For this reason keep S006220.\n",
    "to_drop.append(\"Soltu.Atl_v3.S017940.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faa12bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "step6 = step5[~step5.geneID.isin(to_drop)]\n",
    "step6 = step6.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "789c3e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Syntelog 29457 of 29457\n",
      "Excess Counts:\n",
      "{'Sollyc': 47, '_0G': 319, 'DM': 80, 'Solch': 75, 'Solca': 73}\n",
      "Missing Counts:\n",
      "{'Solch': 7858, 'Sollyc': 9763, '_0G': 22740, '_1G': 13973, '_2G': 12410, '_3G': 11882, '_4G': 13408, 'Solca': 7108}\n",
      "ATL Counts:\n",
      "{0: 5695, 4: 11618, 1: 2828, 2: 3877, 3: 5439}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step6_excess, _, step6_atl = quality_scorer(step6)\n",
    "step6_atl # just double check that the ATL is all good now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e7ba544-24be-403e-ae25-c5cd793e195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is 2 in DM and 2 in either wild, than that feels like it could actually be 2 genes\n",
    "# that were mis-identified as syntelogs; so we should filter those out as well\n",
    "probable_merge = []\n",
    "for gene in step6_excess[\"DM\"]:\n",
    "    if gene in step6_excess[\"Solch\"] or gene in step6_excess[\"Solca\"]:\n",
    "        probable_merge.append(gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c290a7ed-387f-41cf-b040-7d181a0665af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Syntelog 29433 of 29433\n",
      "Excess Counts:\n",
      "{'Sollyc': 40, '_0G': 318, 'DM': 56, 'Solch': 54, 'Solca': 60}\n",
      "Missing Counts:\n",
      "{'Solch': 7858, 'Sollyc': 9755, '_0G': 22721, '_1G': 13962, '_2G': 12401, '_3G': 11873, '_4G': 13397, 'Solca': 7103}\n",
      "ATL Counts:\n",
      "{0: 5691, 4: 11608, 1: 2827, 2: 3871, 3: 5436}\n"
     ]
    }
   ],
   "source": [
    "step7 = step6[~step6.Syntelog.isin(probable_merge)].copy()\n",
    "step7_excess, _, _ = quality_scorer(step7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5666af7f-73a9-46e5-9bb7-6ac8d5551504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is no ATL copy, get rid of that syntelog since it's not useful for the haplotype paper\n",
    "step8_1 = step7.copy()\n",
    "step8_1 = step8_1[step8_1.Syntelog.isin(step8_1[step8_1.species==\"Atl\"].Syntelog)]\n",
    "# we also only want ATL and DM in this final file, both of which are 'Soltu')\n",
    "step8_1 = step8_1[step8_1.geneID.str.contains(\"Soltu\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "53dfefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the other paper, we don't want any problem syntelogs in Solca or Solch\n",
    "keys_to_drop = [\"Solca\", \"Solch\"]\n",
    "step8_2 = step7.copy()\n",
    "for key in keys_to_drop:\n",
    "    step8_2 = step8_2[~step8_2.Syntelog.isin(step7_excess[key])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5e46648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = \"/Users/fekeann/Documents/Lab/RNAseq/Syntelogs/final_selections/publication_output/\"\n",
    "outfile8_1 = outfile+\"syntelogs_atl_only.csv\"\n",
    "outfile8_2 = outfile+\"syntelogs_3species.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f05d53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export just the syntelog and geneID columns\n",
    "outsets = [step8_1, step8_2]\n",
    "outfiles = [outfile8_1, outfile8_2]\n",
    "for i, df in enumerate(outsets):\n",
    "    df.drop([\"species\", \"chromosome\"], axis=1, inplace=True)\n",
    "    df.to_csv(outfiles[i], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
